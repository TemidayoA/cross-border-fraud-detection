{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01: Corridor Analysis\n",
    "\n",
    "This notebook explores the fundamental differences in transaction patterns across payment corridors, demonstrating why a one-size-fits-all fraud detection approach fails.\n",
    "\n",
    "## Objectives\n",
    "1. Generate synthetic transaction data mimicking real corridor patterns\n",
    "2. Visualise how \"normal\" varies dramatically by corridor\n",
    "3. Quantify the false positive problem with global thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('Libraries loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Corridor Data\n",
    "\n",
    "We'll create synthetic data that mirrors real-world corridor patterns observed in cross-border payments. Each corridor has distinct:\n",
    "- Transaction amount distributions\n",
    "- Velocity patterns (transactions per sender per day)\n",
    "- Temporal patterns (time of day, day of week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corridor configuration based on observed patterns\n",
    "CORRIDOR_PROFILES = {\n",
    "    'GBP_NGN': {  # UK to Nigeria\n",
    "        'name': 'UK → Nigeria',\n",
    "        'amount_mean': 450,\n",
    "        'amount_std': 380,\n",
    "        'amount_min': 50,\n",
    "        'amount_max': 5000,\n",
    "        'velocity_mean': 1.8,  # transactions per sender per day\n",
    "        'velocity_std': 1.2,\n",
    "        'peak_hours': [9, 10, 11, 17, 18, 19, 20],  # UTC\n",
    "        'peak_days': [0, 4, 5],  # Monday, Friday, Saturday\n",
    "        'fraud_rate': 0.012,  # 1.2%\n",
    "        'typical_use': 'Family support, school fees, medical bills'\n",
    "    },\n",
    "    'GBP_PLN': {  # UK to Poland\n",
    "        'name': 'UK → Poland',\n",
    "        'amount_mean': 220,\n",
    "        'amount_std': 150,\n",
    "        'amount_min': 30,\n",
    "        'amount_max': 1500,\n",
    "        'velocity_mean': 0.9,\n",
    "        'velocity_std': 0.4,\n",
    "        'peak_hours': [12, 13, 14, 18, 19],\n",
    "        'peak_days': [4, 5],  # Friday, Saturday (end of work week)\n",
    "        'fraud_rate': 0.003,  # 0.3%\n",
    "        'typical_use': 'Worker remittances, monthly family support'\n",
    "    },\n",
    "    'GBP_INR': {  # UK to India\n",
    "        'name': 'UK → India',\n",
    "        'amount_mean': 680,\n",
    "        'amount_std': 520,\n",
    "        'amount_min': 100,\n",
    "        'amount_max': 8000,\n",
    "        'velocity_mean': 1.2,\n",
    "        'velocity_std': 0.8,\n",
    "        'peak_hours': [8, 9, 10, 14, 15, 16],\n",
    "        'peak_days': [0, 1, 2, 3, 4],  # Weekdays\n",
    "        'fraud_rate': 0.006,  # 0.6%\n",
    "        'typical_use': 'Property payments, family events, education'\n",
    "    },\n",
    "    'GBP_PHP': {  # UK to Philippines\n",
    "        'name': 'UK → Philippines',\n",
    "        'amount_mean': 320,\n",
    "        'amount_std': 200,\n",
    "        'amount_min': 40,\n",
    "        'amount_max': 2000,\n",
    "        'velocity_mean': 2.1,\n",
    "        'velocity_std': 1.5,\n",
    "        'peak_hours': [6, 7, 8, 21, 22, 23],  # Early morning/late night UK = daytime PH\n",
    "        'peak_days': [0, 4, 5, 6],  # Monday, Fri-Sun\n",
    "        'fraud_rate': 0.008,  # 0.8%\n",
    "        'typical_use': 'Domestic worker remittances, family support'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f'Configured {len(CORRIDOR_PROFILES)} corridors for analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corridor_transactions(corridor_id, profile, n_transactions=10000, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic transactions for a specific corridor.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate amounts (log-normal distribution, common in financial data)\n",
    "    amounts = np.random.lognormal(\n",
    "        mean=np.log(profile['amount_mean']),\n",
    "        sigma=0.8,\n",
    "        size=n_transactions\n",
    "    )\n",
    "    amounts = np.clip(amounts, profile['amount_min'], profile['amount_max'])\n",
    "    \n",
    "    # Generate timestamps over 90 days\n",
    "    base_date = datetime(2024, 1, 1)\n",
    "    timestamps = []\n",
    "    for _ in range(n_transactions):\n",
    "        day_offset = np.random.randint(0, 90)\n",
    "        \n",
    "        # Weight hours towards peak hours\n",
    "        if np.random.random() < 0.7:  # 70% during peak\n",
    "            hour = np.random.choice(profile['peak_hours'])\n",
    "        else:\n",
    "            hour = np.random.randint(0, 24)\n",
    "        \n",
    "        minute = np.random.randint(0, 60)\n",
    "        ts = base_date + timedelta(days=day_offset, hours=hour, minutes=minute)\n",
    "        timestamps.append(ts)\n",
    "    \n",
    "    # Generate sender IDs (some senders make multiple transactions)\n",
    "    n_unique_senders = int(n_transactions / profile['velocity_mean'] / 30)  # ~monthly active\n",
    "    sender_ids = np.random.choice(\n",
    "        [f'sender_{i:05d}' for i in range(n_unique_senders)],\n",
    "        size=n_transactions,\n",
    "        replace=True\n",
    "    )\n",
    "    \n",
    "    # Generate fraud labels\n",
    "    is_fraud = np.random.random(n_transactions) < profile['fraud_rate']\n",
    "    \n",
    "    # Fraud transactions tend to be higher value\n",
    "    fraud_indices = np.where(is_fraud)[0]\n",
    "    amounts[fraud_indices] *= np.random.uniform(1.5, 3.0, size=len(fraud_indices))\n",
    "    amounts = np.clip(amounts, profile['amount_min'], profile['amount_max'])\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'corridor': corridor_id,\n",
    "        'corridor_name': profile['name'],\n",
    "        'sender_id': sender_ids,\n",
    "        'amount': amounts.round(2),\n",
    "        'timestamp': timestamps,\n",
    "        'is_fraud': is_fraud\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate data for all corridors\n",
    "all_transactions = []\n",
    "for corridor_id, profile in CORRIDOR_PROFILES.items():\n",
    "    df = generate_corridor_transactions(corridor_id, profile, n_transactions=10000)\n",
    "    all_transactions.append(df)\n",
    "    print(f'{profile[\"name\"]}: {len(df):,} transactions, {df[\"is_fraud\"].sum()} fraud cases ({df[\"is_fraud\"].mean()*100:.2f}%)')\n",
    "\n",
    "transactions = pd.concat(all_transactions, ignore_index=True)\n",
    "print(f'\\nTotal: {len(transactions):,} transactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualise Corridor Differences\n",
    "\n",
    "Let's see how dramatically \"normal\" varies by corridor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount distributions by corridor\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (corridor_id, profile) in enumerate(CORRIDOR_PROFILES.items()):\n",
    "    corridor_data = transactions[transactions['corridor'] == corridor_id]\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    ax.hist(corridor_data['amount'], bins=50, edgecolor='white', alpha=0.7)\n",
    "    \n",
    "    # Add percentile lines\n",
    "    median = corridor_data['amount'].median()\n",
    "    p95 = corridor_data['amount'].quantile(0.95)\n",
    "    \n",
    "    ax.axvline(median, color='green', linestyle='--', linewidth=2, label=f'Median: £{median:.0f}')\n",
    "    ax.axvline(p95, color='red', linestyle='--', linewidth=2, label=f'95th %ile: £{p95:.0f}')\n",
    "    \n",
    "    ax.set_title(f'{profile[\"name\"]}\\n{profile[\"typical_use\"]}', fontsize=11)\n",
    "    ax.set_xlabel('Transaction Amount (£)')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('Transaction Amount Distributions by Corridor', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('corridor_amount_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics table\n",
    "summary_stats = transactions.groupby('corridor_name').agg({\n",
    "    'amount': ['median', lambda x: x.quantile(0.95), 'std'],\n",
    "    'is_fraud': ['sum', 'mean']\n",
    "}).round(2)\n",
    "\n",
    "summary_stats.columns = ['Median Amount (£)', '95th Percentile (£)', 'Std Dev', 'Fraud Count', 'Fraud Rate']\n",
    "summary_stats['Fraud Rate'] = (summary_stats['Fraud Rate'] * 100).round(2).astype(str) + '%'\n",
    "\n",
    "print('\\n=== Corridor Summary Statistics ===')\n",
    "print(summary_stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The False Positive Problem with Global Thresholds\n",
    "\n",
    "Let's demonstrate what happens when we apply a single \"flag transactions above £X\" rule globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_global_threshold(transactions, threshold):\n",
    "    \"\"\"\n",
    "    Evaluate a simple global threshold rule.\n",
    "    Flag all transactions above threshold as suspicious.\n",
    "    \"\"\"\n",
    "    flagged = transactions['amount'] > threshold\n",
    "    \n",
    "    results = []\n",
    "    for corridor_name in transactions['corridor_name'].unique():\n",
    "        corridor_data = transactions[transactions['corridor_name'] == corridor_name]\n",
    "        corridor_flagged = flagged[transactions['corridor_name'] == corridor_name]\n",
    "        \n",
    "        # True positives: flagged AND fraud\n",
    "        tp = (corridor_flagged & corridor_data['is_fraud']).sum()\n",
    "        # False positives: flagged AND NOT fraud\n",
    "        fp = (corridor_flagged & ~corridor_data['is_fraud']).sum()\n",
    "        # False negatives: NOT flagged AND fraud\n",
    "        fn = (~corridor_flagged & corridor_data['is_fraud']).sum()\n",
    "        # True negatives: NOT flagged AND NOT fraud\n",
    "        tn = (~corridor_flagged & ~corridor_data['is_fraud']).sum()\n",
    "        \n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'Corridor': corridor_name,\n",
    "            'Flagged': corridor_flagged.sum(),\n",
    "            'True Positives': tp,\n",
    "            'False Positives': fp,\n",
    "            'Recall': f'{recall:.1%}',\n",
    "            'Precision': f'{precision:.1%}',\n",
    "            'False Positive Rate': f'{fpr:.1%}'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Test with global threshold of £1000 (seems reasonable, right?)\n",
    "print('=== Global Threshold: £1,000 ===')\n",
    "print('Rule: Flag all transactions above £1,000 for review\\n')\n",
    "results_1000 = evaluate_global_threshold(transactions, 1000)\n",
    "print(results_1000.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with lower threshold\n",
    "print('\\n=== Global Threshold: £500 ===')\n",
    "print('Rule: Flag all transactions above £500 for review\\n')\n",
    "results_500 = evaluate_global_threshold(transactions, 500)\n",
    "print(results_500.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight\n",
    "\n",
    "Notice the problem:\n",
    "\n",
    "- **£1,000 threshold**: Good precision for UK→Poland (few false positives), but terrible recall for UK→India (misses most fraud because their legitimate transactions are often above £1,000)\n",
    "\n",
    "- **£500 threshold**: Better recall across corridors, but creates massive false positive rates for UK→Nigeria and UK→India\n",
    "\n",
    "**There is no single threshold that works well for all corridors.**\n",
    "\n",
    "This is why we need corridor-specific calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corridor-specific thresholds based on percentiles\n",
    "def evaluate_corridor_specific_thresholds(transactions, percentile=95):\n",
    "    \"\"\"\n",
    "    Use corridor-specific thresholds based on percentile.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for corridor_name in transactions['corridor_name'].unique():\n",
    "        corridor_data = transactions[transactions['corridor_name'] == corridor_name].copy()\n",
    "        \n",
    "        # Calculate corridor-specific threshold\n",
    "        threshold = corridor_data['amount'].quantile(percentile / 100)\n",
    "        \n",
    "        corridor_flagged = corridor_data['amount'] > threshold\n",
    "        \n",
    "        tp = (corridor_flagged & corridor_data['is_fraud']).sum()\n",
    "        fp = (corridor_flagged & ~corridor_data['is_fraud']).sum()\n",
    "        fn = (~corridor_flagged & corridor_data['is_fraud']).sum()\n",
    "        tn = (~corridor_flagged & ~corridor_data['is_fraud']).sum()\n",
    "        \n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'Corridor': corridor_name,\n",
    "            'Threshold': f'£{threshold:.0f}',\n",
    "            'Flagged': corridor_flagged.sum(),\n",
    "            'True Positives': tp,\n",
    "            'False Positives': fp,\n",
    "            'Recall': f'{recall:.1%}',\n",
    "            'Precision': f'{precision:.1%}',\n",
    "            'False Positive Rate': f'{fpr:.1%}'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print('=== Corridor-Specific Thresholds (95th Percentile) ===')\n",
    "print('Rule: Flag transactions above corridor-specific 95th percentile\\n')\n",
    "results_specific = evaluate_corridor_specific_thresholds(transactions, percentile=95)\n",
    "print(results_specific.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement\n",
    "\n",
    "Corridor-specific thresholds achieve **more balanced performance** across corridors. False positive rates are now consistent rather than wildly varying.\n",
    "\n",
    "This is just the beginning—the full system goes beyond simple thresholds to use dynamic signal weighting across multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the synthetic data for use in subsequent notebooks\n",
    "transactions.to_csv('synthetic_transactions.csv', index=False)\n",
    "print(f'Saved {len(transactions):,} transactions to synthetic_transactions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This analysis demonstrates the fundamental problem:\n",
    "\n",
    "1. **Corridors have vastly different baselines** — median transaction in UK→India is 3x that of UK→Poland\n",
    "\n",
    "2. **Global thresholds create impossible tradeoffs** — optimising for one corridor harms another\n",
    "\n",
    "3. **Corridor-specific calibration improves balance** — but we need more sophisticated approaches for production\n",
    "\n",
    "Next notebook: **Feature Engineering** — building corridor-normalised features for the full model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
